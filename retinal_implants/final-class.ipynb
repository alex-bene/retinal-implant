{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "73282a04-5657-4d17-a3cb-92abab7ec51c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pulse2percept.implants import ArgusII, ProsthesisSystem, ElectrodeGrid, DiskElectrode\n",
    "from pulse2percept.models import Model, ScoreboardModel, AxonMapModel\n",
    "from pulse2percept.viz import plot_implant_on_axon_map\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from multiprocessing import cpu_count, Pool\n",
    "import parmap\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImplant(ProsthesisSystem):\n",
    "    def __init__(self, e_num_side, e_radius, spacing=None, total_area=None, stim=None, eye='RE', name = None):\n",
    "        if name is None:\n",
    "            self.name = f\"e_num_side={e_num_side}-e_radius={e_radius}-spacing={spacing}-total_area={total_area}\"\n",
    "        else:\n",
    "            self.name = name\n",
    "\n",
    "        if total_area is not None:\n",
    "            spacing = total_area/(e_num_side - 1)\n",
    "        elif spacing is None:\n",
    "            raise Exception(\"Provide a spacing or total_area parameter in microns\")\n",
    "\n",
    "        self.earray = ElectrodeGrid((e_num_side, e_num_side), x=0, y=0, z=0, rot=0,\n",
    "                                    r=e_radius, spacing=spacing, etype=DiskElectrode,\n",
    "                                    names=('A', '1'))\n",
    "        self.stim   = stim\n",
    "        self.eye    = eye\n",
    "\n",
    "    def plot_on_axon_map(self, annotate_implant=False, annotate_quadrants=True):\n",
    "        plot_implant_on_axon_map(self, annotate_implant=annotate_implant, annotate_quadrants=annotate_quadrants)\n",
    "\n",
    "    def img2stim(self, img):\n",
    "        img   = np.array(img).squeeze()\n",
    "\n",
    "        npwhr = np.where(img > 0.05)\n",
    "        ymin  = min(npwhr[0])\n",
    "        ymax  = max(npwhr[0])\n",
    "        xmin  = min(npwhr[1])\n",
    "        xmax  = max(npwhr[1])\n",
    "\n",
    "        if 2*(xmax - xmin) < (ymax-ymin):\n",
    "            xmin = 0\n",
    "            xmax = img.shape[1]\n",
    "\n",
    "        return resize(img[ymin:ymax, xmin:xmax], self.earray.shape).flatten()\n",
    "\n",
    "    def img2implant_img(self, img):\n",
    "        return np.reshape(self.img2stim(img), self.earray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImplantSimulateDataset():\n",
    "    def __init__(self, implant, trainset, testset, dataset_name, model, base_data_dir,\n",
    "                 train_work_samples=None, test_work_samples=None):\n",
    "        if hasattr(trainset, 'data') and hasattr(testset, 'data'):\n",
    "            self.out_size = np.array(trainset.data[0]).squeeze().shape\n",
    "        else:\n",
    "            raise TypeError(\"Only pytorch dataset objects with data attribute are supported for trainset and testset\")\n",
    "\n",
    "        if str(type(implant)).split('.')[-1][:-2] == 'ArgusII':\n",
    "            self.implant_name = 'ArgusII'\n",
    "        else:\n",
    "            self.implant_name = implant.name\n",
    "\n",
    "        self.implant       = implant\n",
    "        self.dataset_name  = dataset_name\n",
    "        self.model_name    = str(type(model)).split('.')[-1][:-2]\n",
    "        self.model         = model\n",
    "        self.trainset      = trainset\n",
    "        self.testset       = testset\n",
    "        self.base_data_dir = base_data_dir\n",
    "\n",
    "        self.work_with_subset(train_work_samples, test_work_samples)\n",
    "\n",
    "        self.calculate_zipped_args()\n",
    "\n",
    "    def change_implant(self, implant):\n",
    "        self.implant_name = implant.name\n",
    "        self.implant      = implant\n",
    "\n",
    "        self.calculate_and_create_path_names()\n",
    "        self.calculate_zipped_args()\n",
    "\n",
    "    def change_model(self, model):\n",
    "        self.model_name = str(type(model)).split('.')[-1][:-2]\n",
    "        self.model      = model\n",
    "\n",
    "        self.calculate_and_create_path_names()\n",
    "        self.calculate_zipped_args()\n",
    "\n",
    "    def calculate_and_create_path_names(self):\n",
    "        self.percept_path          = os.path.join(self.base_data_dir, self.dataset_name,\n",
    "                                                  'percept', self.model_name+'-'+self.implant_name)\n",
    "        self.percept_path_test  = os.path.join(self.percept_path, 'test')\n",
    "        self.percept_path_train = os.path.join(self.percept_path, 'train')\n",
    "\n",
    "        if not os.path.exists(self.percept_path):\n",
    "            os.makedirs(self.percept_path)\n",
    "        if not os.path.exists(self.percept_path_test):\n",
    "            os.makedirs(self.percept_path_test)\n",
    "        if not os.path.exists(self.percept_path_train):\n",
    "            os.makedirs(self.percept_path_train)\n",
    "\n",
    "    def work_with_subset(self, train_work_samples=None, test_work_samples=None):\n",
    "        def equal_subset(dataset, samples):\n",
    "            data   = np.array(dataset.data)\n",
    "            labels = np.array(dataset.targets)\n",
    "\n",
    "            labels_number     = len(np.unique(labels))\n",
    "            samples_per_label = int(samples/labels_number)\n",
    "\n",
    "            whr_subset = np.concatenate([np.argwhere(labels==i).flatten()[:samples_per_label]\n",
    "                                         for i in range(labels_number)]).flatten()\n",
    "            return (data[whr_subset], labels[whr_subset])\n",
    "\n",
    "        if train_work_samples is not None:\n",
    "            self.dataset_name  = self.dataset_name+'_'+str(train_work_samples)\n",
    "            self.work_trainset = equal_subset(self.trainset, train_work_samples)\n",
    "        else:\n",
    "            self.dataset_name  = self.dataset_name+'_all'\n",
    "            self.work_trainset = (np.array(self.trainset.data), np.array(self.trainset.targets))\n",
    "\n",
    "        if test_work_samples is not None:\n",
    "            self.dataset_name = self.dataset_name+'_'+str(test_work_samples)\n",
    "            self.work_testset = equal_subset(self.testset, test_work_samples)\n",
    "        else:\n",
    "            self.dataset_name = self.dataset_name+'_all'\n",
    "            self.work_testset = (np.array(self.testset.data), np.array(self.testset.targets))\n",
    "\n",
    "        self.calculate_and_create_path_names()\n",
    "\n",
    "    def perc2train(self, percept):\n",
    "        data  = percept.data.squeeze()\n",
    "        npwhr = np.where(data > 0.01)\n",
    "\n",
    "        ymin = min(npwhr[0])\n",
    "        ymax = max(npwhr[0])\n",
    "        xmin = min(npwhr[1])\n",
    "        xmax = max(npwhr[1])\n",
    "\n",
    "        return torch.from_numpy(resize(data[ymin:ymax, xmin:xmax], self.out_size))\n",
    "\n",
    "    def calculate_zipped_args(self):\n",
    "        def zip_args(dataset, path):\n",
    "            all_files = os.listdir(os.path.abspath(path))\n",
    "            excl_file_numbers = []\n",
    "\n",
    "            if all_files is not None:\n",
    "                ex_dataset_files  = list(filter(lambda file: file.endswith('.pt'), all_files))\n",
    "                excl_file_numbers = [int(dataset_file.split('-')[0]) for dataset_file in ex_dataset_files]\n",
    "\n",
    "            data   = dataset[0]\n",
    "            labels = dataset[1]\n",
    "\n",
    "            return [[d, t.item(), i]\n",
    "                    for i, (d, t), in enumerate(zip(data, labels))\n",
    "                    if i not in excl_file_numbers\n",
    "                   ]\n",
    "\n",
    "        self.zipped_test_args  = zip_args(self.work_testset , self.percept_path_test)\n",
    "        self.zipped_train_args = zip_args(self.work_trainset, self.percept_path_train)\n",
    "\n",
    "    def print_info(self, plot=True):\n",
    "        if plot:\n",
    "            self.implant.plot_on_axon_map()\n",
    "        print(self)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__repr__()+\"\\n\" + \\\n",
    "               f\"Implant Name      : {self.implant_name}\\n\" + \\\n",
    "               f\"Model   Name      : {self.model_name}\\n\" + \\\n",
    "               f\"Dataset Name      : {self.dataset_name}\\n\" + \\\n",
    "               f\"Output  Directory : {self.percept_path}\\n\" + \\\n",
    "               f\"Number of train samples to simulate: {len(self.zipped_train_args)}\\n\" + \\\n",
    "               f\"Number of test  samples to simulate: {len(self.zipped_test_args)}\"\n",
    "\n",
    "    def one_loop(self, img, label, idx, path):\n",
    "        img = np.array(img).squeeze()\n",
    "\n",
    "        self.implant.stim = self.implant.img2stim(img)\n",
    "        percept = self.model.predict_percept(self.implant)\n",
    "        img = self.perc2train(percept)\n",
    "        torch.save(img, os.path.join(path, f'{idx}-{label}.pt'))\n",
    "\n",
    "    def one_train_loop(self, img, label, idx):\n",
    "        self.one_loop(img, label, idx, self.percept_path_train)\n",
    "\n",
    "    def one_test_loop(self, img, label, idx):\n",
    "        self.one_loop(img, label, idx, self.percept_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_train_loop(img, label, idx):\n",
    "    isd.one_loop(img, label, idx, isd.percept_path_train)\n",
    "\n",
    "def one_test_loop(img, label, idx):\n",
    "    isd.one_loop(img, label, idx, isd.percept_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ScoreboardModel(engine='serial', grid_type='rectangular', \n",
       "                n_jobs=1, rho=100, scheduler='threading', \n",
       "                spatial=ScoreboardSpatial, temporal=None, \n",
       "                thresh_percept=0, verbose=True, \n",
       "                xrange=(-20, 20), xystep=0.25, \n",
       "                yrange=(-15, 15))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize models\n",
    "axonMap_model    = AxonMapModel()\n",
    "scoreBoard_model = ScoreboardModel()\n",
    "\n",
    "# Build models\n",
    "axonMap_model.build()\n",
    "scoreBoard_model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform   = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "trainset    = datasets.MNIST('./data', download=True, train=True,  transform=transform)\n",
    "testset     = datasets.MNIST('./data', download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current electrode radius in microns   is : 10\n",
      "Current electrode numbers per side    is : 25\n",
      "Current implant total area in microns is : 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:54<00:00, 36.88it/s]\n",
      "100%|██████████| 400/400 [00:12<00:00, 32.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current electrode radius in microns   is : 20\n",
      "Current electrode numbers per side    is : 25\n",
      "Current implant total area in microns is : 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2000/2000 [01:14<00:00, 26.67it/s]\n",
      "100%|██████████| 400/400 [00:19<00:00, 20.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current electrode radius in microns   is : 30\n",
      "Current electrode numbers per side    is : 25\n",
      "Current implant total area in microns is : 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2000/2000 [01:29<00:00, 22.34it/s]\n",
      "100%|██████████| 400/400 [00:16<00:00, 24.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current electrode radius in microns   is : 40\n",
      "Current electrode numbers per side    is : 25\n",
      "Current implant total area in microns is : 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:28<00:00, 22.58it/s]\n",
      "100%|██████████| 400/400 [00:15<00:00, 25.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current electrode radius in microns   is : 50\n",
      "Current electrode numbers per side    is : 25\n",
      "Current implant total area in microns is : 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2000/2000 [01:27<00:00, 22.85it/s]\n",
      "100%|██████████| 400/400 [00:18<00:00, 21.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current electrode radius in microns   is : 60\n",
      "Current electrode numbers per side    is : 25\n",
      "Current implant total area in microns is : 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2000/2000 [01:25<00:00, 23.43it/s]\n",
      "100%|██████████| 400/400 [00:18<00:00, 21.89it/s]\n"
     ]
    }
   ],
   "source": [
    "e_radiuses = [e_radius for e_radius in range(10, 61, 10)]\n",
    "e_num_side = 25\n",
    "total_area = 4000\n",
    "\n",
    "custom_implant = CustomImplant(e_num_side=e_num_side, e_radius=e_radiuses[0], total_area=total_area)\n",
    "isd = ImplantSimulateDataset(custom_implant, trainset, testset, 'MNIST', scoreBoard_model, './data',\n",
    "                             train_work_samples=2000, test_work_samples=400)\n",
    "\n",
    "with Pool(processes = cpu_count()) as pool:\n",
    "    for e_radius in e_radiuses:\n",
    "        print(f\"Current electrode radius in microns   is : {e_radius}\")\n",
    "        print(f\"Current electrode numbers per side    is : {e_num_side}\")\n",
    "        print(f\"Current implant total area in microns is : {total_area}\")\n",
    "        custom_implant = CustomImplant(e_num_side=e_num_side, e_radius=e_radius, total_area=total_area)\n",
    "        isd.change_implant(custom_implant)\n",
    "\n",
    "        parmap.starmap(one_train_loop, isd.zipped_train_args,\n",
    "                       pm_pbar=True, pm_processes=cpu_count(), pm_chunksize=5)\n",
    "\n",
    "        parmap.starmap(one_test_loop, isd.zipped_test_args,\n",
    "                       pm_pbar=True, pm_processes=cpu_count(), pm_chunksize=5)"
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "15559035-ef61-4565-a93d-7a39922190cc",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
